{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import GetOldTweets3 as got \n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def get_text_from_url(url):\n",
    "    if url:\n",
    "        try:\n",
    "            soup = BeautifulSoup(requests.get(url).text, 'html.parser')\n",
    "            return \" \".join([p.get_text().replace(u'\\xa0', u' ') for p in soup.find_all('p')])\n",
    "        except:\n",
    "            return \"\"\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "def get_urls(text):\n",
    "    return re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text)\n",
    "\n",
    "def get_tweets(keywords, start=\"2020-04-01\", stop=\"2020-04-16\", maxTweets=0):\n",
    "    tweetCriteria = got.manager.TweetCriteria().setQuerySearch(keywords)\\\n",
    "                                             .setSince(start)\\\n",
    "                                             .setUntil(stop)\\\n",
    "                                             .setMaxTweets(maxTweets)\\\n",
    "                                             .setLang('de')\\\n",
    "                                             .setNear('Berlin, Germany')\\\n",
    "                                             .setWithin('1000km') \n",
    "    tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "    tweet_dicts = []\n",
    "    for tweet in tweets:\n",
    "        tweet_dict = tweet.__dict__ \n",
    "        tweet_dict['url_text'] = get_text_from_url(tweet.urls)\n",
    "        tweet_dicts.append(tweet_dict)\n",
    "\n",
    "    return tweet_dicts\n",
    "\n",
    "def get_top_words(model, feature_names, n_top_words):\n",
    "    topics = {}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topics[topic_idx] = \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "    return topics\n",
    "\n",
    "def get_topics(texts, n_components=20, n_top_words = 20, n_features=int(1e12)):\n",
    "    vect = CountVectorizer(max_df=0.5, \n",
    "                           min_df=5,\n",
    "                           max_features=n_features, \n",
    "                           stop_words=get_stop_words('de'))\n",
    "    lda = LatentDirichletAllocation(n_components=n_components, max_iter=200,\n",
    "                                learning_method='online',\n",
    "                                random_state=0)\n",
    "    tf = vect.fit_transform(texts)\n",
    "    lda.fit(tf)\n",
    "    topic_assignments = lda.transform(tf)\n",
    "    tf_feature_names = vect.get_feature_names()\n",
    "    topics_dict = get_top_words(lda, tf_feature_names, n_top_words)\n",
    "    \n",
    "    # sort topics by occurrence\n",
    "    topic_loadings = topic_assignments.sum(axis=0).argsort()[:-1:]\n",
    "    topic_assignments = topic_assignments[:,topic_loadings]\n",
    "    topics = [topics_dict[topic_idx] for topic_idx in topic_loadings]\n",
    "    return topic_assignments.argmax(axis=1), topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c77b8a099ae409996887184ce45fecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='covid deutschland', description='keywords'), DatePicker(value=Timestamp('202â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import widgets\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "@widgets.interact_manual(num_topics=(2, 20),\n",
    "                         text_source=['tweets','urls in tweets'],\n",
    "                         max_tweets=(0, 10000)\n",
    "                        )\n",
    "def plot_tweets(keywords=\"covid deutschland\", \n",
    "         start=widgets.DatePicker(value=pd.to_datetime('2020-01-01')), \n",
    "         stop=widgets.DatePicker(value=pd.to_datetime('2020-04-16')), \n",
    "         num_topics=10,\n",
    "         text_source='tweets',\n",
    "         max_tweets=0\n",
    "        ):\n",
    "    print(f\"Fetching tweets for keywords {keywords}\")\n",
    "    tweets = get_tweets(keywords, start.strftime('%Y-%m-%d'), stop.strftime('%Y-%m-%d'), maxTweets=100)\n",
    "    if tweets:\n",
    "        print(f'Found {len(tweets)} tweets')\n",
    "        df = pd.DataFrame(tweets).set_index('date')\n",
    "        if text_source == 'tweets':\n",
    "            df['topics'], text_topics = get_topics(df['text'], n_components=num_topics, n_top_words=5)\n",
    "        elif text_source == 'urls in tweets':\n",
    "            df['topics'], text_topics = get_topics(df['url_text'], n_components=num_topics, n_top_words=5)\n",
    "        pd.get_dummies(df['topics']).resample('D').sum().plot(marker='o')\n",
    "        plt.legend(range(len(text_topics)));\n",
    "        display(df)#[['text', 'urls', 'topics']])\n",
    "        print(\"\\n\".join([f'Topic {idx}: {text}' for idx, text in enumerate(text_topics)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('ppp': conda)",
   "language": "python",
   "name": "python361064bitpppconda08cb32434e5c43ab89b88a4949d5ebb2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
